# Stereo (2D to Point Cloud 3D)

This repository provides a method for generating 3D point clouds from stereo images using deep learning models. The process involves the following steps:

1. **Disparity Estimation**: Stereo images are processed using the PSMNet model to compute the pixel-wise disparity between corresponding points in the left and right images.

2. **Point Cloud Generation**: Using the disparity maps, 3D point clouds are generated by reprojecting the disparity values into 3D space. Each pixel in the disparity map corresponds to a 3D point in the point cloud.

3. **Point Cloud Visualization**: The generated point clouds can be visualized using various tools and libraries such as Open3D or Mayavi for further analysis and interpretation.

By following the provided method, users can convert pairs of stereo images into 3D point clouds, enabling depth perception and scene reconstruction from 2D image data.

## Sample Outputs

For examples of the generated outputs produced by this repository, please check out the 'Sample_Output' folder. You'll find sample images, disparity maps, and point cloud visualizations to get an idea of the results obtained from the provided method.

**Note**: It's essential to install the required libraries mentioned in the `requirements.txt` file before running the code. Additionally, stay tuned as I will soon upload the code for training custom disparity maps on your dataset. I am also working on segmenting the generated point clouds and will upload that as well in the near future.
