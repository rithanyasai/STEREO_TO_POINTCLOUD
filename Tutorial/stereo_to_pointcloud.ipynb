{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1Bz8H0WSCbU2Lr2Urmo0o1aMfW0B1uWr1","authorship_tag":"ABX9TyPU65Ujknd5EB1XjmQl7UJz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQIS_QaqXxfj","executionInfo":{"status":"ok","timestamp":1716012186269,"user_tz":-330,"elapsed":3667,"user":{"displayName":"haya haya","userId":"09623373004327866029"}},"outputId":"6ecfa5fb-b55c-483f-81e9-a3982f797e06"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/rithanya/darri_pipeline/STEREO_TO_PC"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JlrXaPs-YYGy","executionInfo":{"status":"ok","timestamp":1716015464499,"user_tz":-330,"elapsed":7,"user":{"displayName":"haya haya","userId":"09623373004327866029"}},"outputId":"c5760cd8-f6ea-4be4-dbf4-5ae89c180099"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/rithanya/darri_pipeline/STEREO_TO_PC\n"]}]},{"cell_type":"code","source":["#@title GET THE CALIBERATION DATA, WE FOCUS ON Q MATRIX\n","import numpy as np\n","import cv2\n","\n","def parse_calibration_and_compute_Q(filepath):\n","    \"\"\"Parse KITTI calibration file and compute Q matrix.\"\"\"\n","    data = {}\n","    with open(filepath, 'r') as f:\n","        for line in f.readlines():\n","            if ':' in line:\n","                key, value = line.split(':')\n","                data[key] = np.array([float(x) for x in value.split()])\n","\n","    # Extract camera parameters\n","    P2 = data['P2'].reshape(3, 4)\n","    P3 = data['P3'].reshape(3, 4)\n","    f = P2[0, 0]\n","    cx, cy = P2[0, 2], P2[1, 2]\n","    Tx = P3[0, 3] / (-f)\n","\n","    # Compute Q matrix\n","    Q = np.zeros((4, 4))\n","    Q[0, 0] = Q[1, 1] = 1\n","    Q[0, 3] = -cx\n","    Q[1, 3] = -cy\n","    Q[2, 3] = f\n","    Q[3, 2] = -1 / Tx\n","    Q[3, 3] = (cx - P3[0, 2]) / Tx  # cx' - cx\n","\n","    return data, Q\n","\n","# Example usage\n","calib_data, Q_matrix = parse_calibration_and_compute_Q('/content/drive/MyDrive/rithanya/DARRI_PSUEDO_LIDAR/deep_learning_disparity/0000.txt')\n","print(\"Calibration data:\")\n","print(calib_data)\n","print(\"\\nQ matrix:\")\n","print(Q_matrix)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFg141swa9rk","executionInfo":{"status":"ok","timestamp":1716018901730,"user_tz":-330,"elapsed":420,"user":{"displayName":"haya haya","userId":"09623373004327866029"}},"outputId":"e7e862dc-9a44-4ea1-c3fd-3d1fac7c4396"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Calibration data:\n","{'P0': array([721.5377,   0.    , 609.5593,   0.    ,   0.    , 721.5377,\n","       172.854 ,   0.    ,   0.    ,   0.    ,   1.    ,   0.    ]), 'P1': array([ 721.5377,    0.    ,  609.5593, -387.5744,    0.    ,  721.5377,\n","        172.854 ,    0.    ,    0.    ,    0.    ,    1.    ,    0.    ]), 'P2': array([7.215377e+02, 0.000000e+00, 6.095593e+02, 4.485728e+01,\n","       0.000000e+00, 7.215377e+02, 1.728540e+02, 2.163791e-01,\n","       0.000000e+00, 0.000000e+00, 1.000000e+00, 2.745884e-03]), 'P3': array([ 7.215377e+02,  0.000000e+00,  6.095593e+02, -3.395242e+02,\n","        0.000000e+00,  7.215377e+02,  1.728540e+02,  2.199936e+00,\n","        0.000000e+00,  0.000000e+00,  1.000000e+00,  2.729905e-03])}\n","\n","Q matrix:\n","[[   1.            0.            0.         -609.5593    ]\n"," [   0.            1.            0.         -172.854     ]\n"," [   0.            0.            0.          721.5377    ]\n"," [   0.            0.           -2.12514366    0.        ]]\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/rithanya/darri_pipeline/STEREO_TO_PC"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RJsm1I4asfX3","executionInfo":{"status":"ok","timestamp":1716018880132,"user_tz":-330,"elapsed":476,"user":{"displayName":"haya haya","userId":"09623373004327866029"}},"outputId":"673c73ac-1ea4-4f5a-e2e6-9f0c5f427592"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/rithanya/darri_pipeline/STEREO_TO_PC\n"]}]},{"cell_type":"code","source":["# disparity_video_processing.py\n","\n","import os\n","import cv2\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from PSMnet_for_disparity import PSMNet, test_PSM\n","\n","# Initialize CUDA, model, and other variables\n","cuda_present = torch.cuda.is_available()\n","maxdisp = 192\n","# Path for left and right images\n","left_folder_path = \"/content/drive/MyDrive/rithanya/darri_pipeline/DARRI_PIPE_CHECK/LEFT\"\n","rght_folder_path = \"/content/drive/MyDrive/rithanya/darri_pipeline/DARRI_PIPE_CHECK/RIGHT\"\n","\n","# Pretrained model path\n","pretrained_model_path = \"/content/drive/MyDrive/rithanya/DARRI_PSUEDO_LIDAR/deep_learning_disparity/pretrained_model_KITTI2012.tar raw=true\"\n","\n","# Output folders\n","output_folder = \"/content/drive/MyDrive/rithanya/darri_pipeline/DARRI_PIPE_CHECK/OUTPUT/disparity2/\"\n","disp_npy_op = \"/content/drive/MyDrive/rithanya/darri_pipeline/DARRI_PIPE_CHECK/OUTPUT/disp_numpy2/\"\n","ply_output_folder = \"/content/drive/MyDrive/rithanya/darri_pipeline/DARRI_PIPE_CHECK/OUTPUT/pointcloud_op2/\"\n","\n","model = PSMNet(maxdisp)\n","\n","if cuda_present:\n","    torch.cuda.manual_seed(1)\n","    model = nn.DataParallel(model)\n","    model.cuda()\n","\n","state_dict = torch.load(pretrained_model_path)\n","model.load_state_dict(state_dict['state_dict'])\n","\n","# Ensure output directories exist\n","os.makedirs(output_folder, exist_ok=True)\n","os.makedirs(disp_npy_op, exist_ok=True)\n","os.makedirs(ply_output_folder, exist_ok=True)\n","\n","# Get sorted lists of left and right image file names\n","left_images = sorted([img for img in os.listdir(left_folder_path)])\n","rght_images = sorted([img for img in os.listdir(rght_folder_path)])\n","\n","# Process each image pair\n","for left_image_name, rght_image_name in zip(left_images, rght_images):\n","    left_image_path = os.path.join(left_folder_path, left_image_name)\n","    rght_image_path = os.path.join(rght_folder_path, rght_image_name)\n","\n","    disp_img = test_PSM(model, left_image_path, rght_image_path, cuda_present)\n","    disp = np.array(disp_img, dtype=np.float64)\n","    disp = cv2.normalize(disp, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n","\n","    np.save(os.path.join(disp_npy_op, f\"disparity_{left_image_name.split('.')[0]}.npy\"), disp)\n","    cv2.imwrite(os.path.join(output_folder, f\"disparity_{left_image_name.split('.')[0]}.png\"), disp)\n","\n","    # Generate Point Cloud from Disparity Map\n","    colors = cv2.cvtColor(cv2.imread(left_image_path), cv2.COLOR_BGR2RGB)\n","    mask_map = disp > disp.min()\n","    output_points = cv2.reprojectImageTo3D(disp, Q_matrix)[mask_map]\n","    output_colors = colors[mask_map]\n","\n","    def create_point_cloud_file(vertices, colors, filename):\n","        colors = colors.reshape(-1, 3)\n","        vertices = np.hstack([vertices.reshape(-1, 3), colors])\n","        ply_header = '''ply\n","        format ascii 1.0\n","        element vertex %(vert_num)d\n","        property float x\n","        property float y\n","        property float z\n","        property uchar red\n","        property uchar green\n","        property uchar blue\n","        end_header\n","        '''\n","        with open(filename, 'w') as f:\n","            f.write(ply_header % dict(vert_num=len(vertices)))\n","            np.savetxt(f, vertices, '%f %f %f %d %d %d')\n","\n","    output_file = os.path.join(ply_output_folder, f'pointCloud_{left_image_name.split(\".\")[0]}.ply')\n","    create_point_cloud_file(output_points, output_colors, output_file)\n"],"metadata":{"id":"tJarQVGlYmbC","executionInfo":{"status":"ok","timestamp":1716018918919,"user_tz":-330,"elapsed":11059,"user":{"displayName":"haya haya","userId":"09623373004327866029"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#@title visualize \"a\" point_cloud USING OPEN3D\n","\n","import open3d as o3d\n","import numpy as np\n","\n","# Replace 'path_to_your_ply_file.ply' with the path to your PLY file\n","ply_file_path = '/content/drive/MyDrive/rithanya/darri_pipeline/DARRI_PIPE_CHECK/OUTPUT/pointcloud_op/pointCloud_000029L.ply'\n","\n","# Load your own PLY point cloud\n","pcd = o3d.io.read_point_cloud(ply_file_path)\n","\n","# Print the point cloud\n","print(pcd)\n","print(np.asarray(pcd.points))\n","\n","# Visualize the point cloud\n","o3d.visualization.draw_geometries([pcd])\n"],"metadata":{"id":"gWZX3W2gfRWs","colab":{"base_uri":"https://localhost:8080/","height":208},"executionInfo":{"status":"ok","timestamp":1716015359293,"user_tz":-330,"elapsed":3141,"user":{"displayName":"haya haya","userId":"09623373004327866029"}},"outputId":"3674a859-102f-4336-df68-9a1cc3db4777"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["PointCloud with 465749 points.\n","[[ 32.557705   9.232456 -38.538681]\n"," [ 32.504292   9.232456 -38.538681]\n"," [ 39.29599   11.179928 -46.667934]\n"," ...\n"," [ -1.190061  -0.3803    -1.364186]\n"," [ -1.186694  -0.378622  -1.358168]\n"," [ -1.176857  -0.374889  -1.344776]]\n","\u001b[1;33m[Open3D WARNING] GLFW Error: X11: The DISPLAY environment variable is missing\u001b[0;m\n","\u001b[1;33m[Open3D WARNING] Failed to initialize GLFW\u001b[0;m\n","\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"]}]},{"cell_type":"code","source":["#@title Visualize a \"video\" pointclouds USING MAYAVI\n","\n","import os\n","import open3d as o3d\n","import numpy as np\n","import mayavi.mlab as mlab\n","\n","def visualize_point_clouds(input_dir, output_dir):\n","    def rotate_x(points, angle):\n","        theta = np.radians(angle)\n","        c, s = np.cos(theta), np.sin(theta)\n","        R = np.array([\n","            [1, 0, 0],\n","            [0, c, -s],\n","            [0, s, c]\n","        ])\n","        return np.dot(points, R.T)\n","\n","    def rotate_z(points, angle):\n","        theta = np.radians(angle)\n","        c, s = np.cos(theta), np.sin(theta)\n","        R = np.array([\n","            [c, -s, 0],\n","            [s, c, 0],\n","            [0, 0, 1]\n","        ])\n","        return np.dot(points, R.T)\n","\n","    input_files = os.listdir(input_dir)\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for i, file_nm in enumerate(input_files):\n","        pcd = o3d.io.read_point_cloud(os.path.join(input_dir, file_nm))\n","        pcloud = np.array(pcd.points)\n","        colors = np.array(pcd.colors)\n","        rgba_colors = np.ones((colors.shape[0], 4))\n","        rgba_colors[:, :3] = colors\n","\n","        pcloud_rotated = pcloud.copy()\n","        pcloud_rotated[:, 2] = -pcloud_rotated[:, 2]\n","        pcloud_rotated[:, 0] = -pcloud_rotated[:, 0]\n","        pcloud_fig = mlab.figure(bgcolor=(0, 0, 0), size=(1280, 720))\n","        mlab.clf()\n","        plot = mlab.points3d(pcloud_rotated[:, 0], pcloud_rotated[:, 1], pcloud_rotated[:, 2], np.arange(len(pcloud_rotated)), mode='point', figure=pcloud_fig)\n","        plot.module_manager.scalar_lut_manager.lut.table = (rgba_colors * 255).astype(np.uint8)\n","\n","        mlab.view(azimuth=270, distance=10, elevation=10, focalpoint=np.mean(pcloud_rotated, axis=0))\n","        mlab.savefig(filename=os.path.join(output_dir, f'pointcloud_{i:02d}.png'))\n","        mlab.close(all=True)\n","\n","# Usage\n","input_dir = \"pointcloud_output_folder0006-20240515T141019Z-001/pointcloud_output_folder0006/\"\n","output_dir = \"pointcloud_img0006/\"\n","visualize_point_clouds(input_dir, output_dir)\n"],"metadata":{"id":"cGPLou4xg6Ax"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title after checking the point_cloud_representations, you can create a video\n","import os\n","import cv2\n","from tqdm import tqdm\n","\n","def create_point_cloud_video(input_dir, output_video_path, fps=1, codec='VP80'):\n","    \"\"\"\n","    Creates a video from images stored in a directory.\n","\n","    Parameters:\n","    - input_dir (str): Path to the directory containing point-cloud images.\n","    - output_video_path (str): Path to the output video file.\n","    - fps (int): Frames per second for the video. Default is 1.\n","    - codec (str): Codec to be used for video. Default is 'VP80'.\n","    \"\"\"\n","    fourcc = cv2.VideoWriter_fourcc(*codec)\n","    writer = None\n","\n","    for file in tqdm(os.listdir(input_dir)):\n","        img_path = os.path.join(input_dir, file)\n","\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            continue\n","\n","        if writer is None:\n","            writer = cv2.VideoWriter(output_video_path, fourcc, fps, (img.shape[1], img.shape[0]), True)\n","\n","        if writer is not None:\n","            writer.write(img)\n","\n","    if writer is not None:\n","        writer.release()\n","\n","input_dir = \"normal/0000/0000/\"\n","output_video_path = \"0000_video.webm\"\n","create_point_cloud_video(input_dir, output_video_path)\n"],"metadata":{"id":"DnpF4fK3j8d5"},"execution_count":null,"outputs":[]}]}